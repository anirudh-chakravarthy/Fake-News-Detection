{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24377,
     "status": "ok",
     "timestamp": 1565029334749,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "0wqDd3dfdIEp",
    "outputId": "52d4108b-862c-4fea-9e43-8ffc74c8298c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd drive/My\\ Drive/NUS-Fake-News-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25593,
     "status": "ok",
     "timestamp": 1565029336135,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "w1z2vdlor2ZN",
    "outputId": "4a180764-9b35-4309-9623-d6b02c2e540e"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Bidirectional, CuDNNGRU, CuDNNLSTM, Activation,\\\n",
    "                        Dense, Input, concatenate, Dropout, GlobalMaxPool1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# random seed for reproducibility\n",
    "np.random.seed(4123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-cAkmNEsPPK"
   },
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33653,
     "status": "ok",
     "timestamp": 1565029344586,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "EI_ckpG3snCf",
    "outputId": "e2ee7ecb-22aa-405f-dee7-96777db8b134"
   },
   "outputs": [],
   "source": [
    "!ls dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9O-26dZsOil"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train2.tsv', sep='\\t')\n",
    "val_df = pd.read_csv('dataset/val2.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('dataset/test2.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VRDiuEgtpFt"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTSzsdYfwfg6"
   },
   "source": [
    "## Creating embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12944,
     "status": "ok",
     "timestamp": 1565029367502,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "EZzhOjZ0we6B",
    "outputId": "df61312a-0259-4746-9704-0d170e250341"
   },
   "outputs": [],
   "source": [
    "def readGloveFile(gloveFile):\n",
    "    with open(gloveFile, 'r') as f:\n",
    "        wordToGlove = {}  # map from a token (word) to a Glove embedding vector\n",
    "        wordToIndex = {}  # map from a token to an index\n",
    "        indexToWord = {}  # map from an index to a token \n",
    "\n",
    "        for line in f:\n",
    "            record = line.strip().split()\n",
    "            token = record[0] # take the token (word) from the text line\n",
    "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) # associate the Glove embedding vector to a that token (word)\n",
    "\n",
    "        tokens = sorted(wordToGlove.keys())\n",
    "        for idx, tok in enumerate(tokens):\n",
    "            kerasIdx = idx + 1\n",
    "            wordToIndex[tok] = kerasIdx # associate an index to a token (word)\n",
    "            indexToWord[kerasIdx] = tok # associate a word to a token (word). Note: inverse of dictionary above\n",
    "\n",
    "    return wordToIndex, indexToWord, wordToGlove\n",
    "\n",
    "# Create Pretrained Keras Embedding Layer\n",
    "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable, inputLayer=None):\n",
    "    vocabLen = len(wordToIndex) + 1  # adding 1 to account for masking\n",
    "    embDim = next(iter(wordToGlove.values())).shape[0]\n",
    "\n",
    "    embeddingMatrix = np.zeros((vocabLen, embDim))  # initialize with zeros\n",
    "    for word, index in wordToIndex.items():\n",
    "        embeddingMatrix[index, :] = wordToGlove[word] # create embedding: word index to Glove word embedding\n",
    "\n",
    "    if inputLayer is None:\n",
    "        embeddingLayer = Embedding(vocabLen, embDim, weights=[embeddingMatrix], trainable=isTrainable)\n",
    "    else:\n",
    "        embeddingLayer = Embedding(vocabLen, embDim, weights=[embeddingMatrix], trainable=isTrainable) (inputLayer)\n",
    "    return embeddingLayer\n",
    "\n",
    "wordToIndex, indexToWord, wordToGlove = readGloveFile('glove.6B.100d.txt')\n",
    "pretrainedEmbeddingLayer = createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADHziK_hw3P4"
   },
   "source": [
    "## Loading relevant data corresponding to the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHg5qltjtlFP"
   },
   "outputs": [],
   "source": [
    "# mapping labels to integers\n",
    "def process_labels(labels, classifier):\n",
    "    if classifier == 'binary':\n",
    "        labels = labels.replace({'half-true': 1, 'mostly-true': 1, 'true': 1, \n",
    "                                 'barely-true': 0, 'pants-fire': 0, 'false': 0})\n",
    "    else:\n",
    "        labels = labels.replace({'pants-fire': 0, 'false': 1, 'barely-true': 2, \n",
    "                                 'half-true': 3, 'mostly-true': 4, 'true': 5})\n",
    "    return labels  \n",
    "\n",
    "\n",
    "def s_condition(df, classifier='sixway'):\n",
    "    labels = df.iloc[:, 2]\n",
    "    labels = process_labels(labels, classifier)\n",
    "    \n",
    "    data = df.iloc[:, 3].tolist()\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(data)\n",
    "    tokens = t.texts_to_sequences(data)\n",
    "    data = pad_sequences(tokens)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def sj_condition(df, classifier='sixway'):\n",
    "    labels = df.iloc[:, 2]\n",
    "    labels = process_labels(labels, classifier)\n",
    "    \n",
    "    statement = df.iloc[:, 3]\n",
    "    justification = df.iloc[:, 15]\n",
    "    data = (statement.map(str) + justification.map(str)).tolist()\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(data)\n",
    "    tokens = t.texts_to_sequences(data)\n",
    "    data = pad_sequences(tokens)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def sjplus_condition(df, classifier='sixway'):\n",
    "    labels = df.iloc[:, 2]\n",
    "    labels = process_labels(labels, classifier)\n",
    "    \n",
    "    statement = df.iloc[:, 3]\n",
    "    statement = statement.map(str).tolist()\n",
    "    justification = df.iloc[:, 15]\n",
    "    justification = justification.map(str).tolist()\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(statement + justification)\n",
    "    tokens = t.texts_to_sequences(statement)\n",
    "    statement = pad_sequences(tokens, maxlen=800)\n",
    "    tokens = t.texts_to_sequences(justification)\n",
    "    justification = pad_sequences(tokens, maxlen=800)\n",
    "\n",
    "    data = [statement, justification]\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jS1NrvXew7yg"
   },
   "source": [
    "## Creating models based for each conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgg0wEd8vnIl"
   },
   "outputs": [],
   "source": [
    "def s_model(classifier='sixway'):\n",
    "    model = Sequential()\n",
    "    model.add(pretrainedEmbeddingLayer)\n",
    "    model.add(Bidirectional(CuDNNLSTM(32)))\n",
    "    model.add(Dropout(0.4))\n",
    "    if classifier == 'binary':\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def sj_model(classifier='sixway'):\n",
    "    model = Sequential()\n",
    "    model.add(pretrainedEmbeddingLayer)\n",
    "    model.add(Bidirectional(CuDNNLSTM(32)))\n",
    "    \n",
    "    if classifier == 'binary':\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def sjplus_model(input_dims, classifier='sixway'):\n",
    "    input1 = Input(shape=(input_dims[0],))\n",
    "    x1 = createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, False, input1)\n",
    "    x1 = Dropout(0.2) (x1)\n",
    "    x1 = Bidirectional(CuDNNGRU(32, return_sequences=True)) (x1)\n",
    "    x1 = Dropout(0.2) (x1)\n",
    "    x1 = Bidirectional(CuDNNLSTM(32, return_sequences=True)) (x1)\n",
    "    x1 = Dropout(0.2) (x1)\n",
    "    x1 = GlobalMaxPool1D()(x1)\n",
    "    x1 = Dense(50, activation=\"relu\")(x1)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    model1 = Model(inputs=input1, outputs=x1)\n",
    "\n",
    "    input2 = Input(shape=(input_dims[1],))\n",
    "    x2 = createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, False, input2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    x2 = Bidirectional(CuDNNGRU(32, return_sequences=True)) (x2)\n",
    "    x2 = Dropout(0.2) (x2)\n",
    "    x2 = Bidirectional(CuDNNLSTM(32, return_sequences=True,)) (x2)\n",
    "    x2 = Dropout(0.2) (x2)\n",
    "    x2 = GlobalMaxPool1D()(x2)\n",
    "    x2 = Dense(50, activation=\"relu\")(x2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    model2 = Model(inputs=input2, outputs=x2)\n",
    "    \n",
    "    x = concatenate([model1.output, model2.output])\n",
    "    if classifier == 'binary':\n",
    "        out = Dense(1, activation='sigmoid') (x)\n",
    "    else:\n",
    "        out = Dense(6, activation='softmax') (x)\n",
    "    model = Model(inputs=[model1.input, model2.input], outputs=out)\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7HEYL9D24or"
   },
   "source": [
    "# Training the model\n",
    "Experiments:\n",
    "1. Batch size\n",
    "2. S / SJ / SJ+ conditions\n",
    "3. Dropout/ dense layers\n",
    "4. CuDNNLSTM for faster training\n",
    "5. Warm-up strategy\n",
    "6. Learning rate\n",
    "7. Added GRU layer\n",
    "8. Bias to minority class\n",
    "9. Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yx2Lr7aW8tuh"
   },
   "outputs": [],
   "source": [
    "ckpt_path = 'fake_news_sixway.hdf5'\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1, restore_best_weights=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, verbose=1, min_lr=1.e-6)\n",
    "modelckpt_cb = ModelCheckpoint(ckpt_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# tb = TensorBoard()\n",
    "\n",
    "callbacks = [earlystop, reducelr, modelckpt_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20593,
     "status": "error",
     "timestamp": 1565029486174,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "-BR54AVjkKNz",
    "outputId": "cabb2826-2dbe-424c-d487-b90b2fc4632c"
   },
   "outputs": [],
   "source": [
    "classifier = 'sixway'\n",
    "batch_size = 32\n",
    "np.random.seed(4123)\n",
    "\n",
    "x_train, y_train = sjplus_condition(train_df, classifier)\n",
    "x_val, y_val = sjplus_condition(val_df, classifier)\n",
    "\n",
    "sixway_model = sjplus_model([len(x_train[0][0]), len(x_train[1][0])], classifier)\n",
    "sixway_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=1.e-6), metrics=['acc'])\n",
    "sixway_history = sixway_model.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
    "                                   batch_size=batch_size, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15773,
     "status": "error",
     "timestamp": 1565029512204,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "s6hP3DDZdBvR",
    "outputId": "eab3f0b1-79ed-45d0-e195-17317638cd9a"
   },
   "outputs": [],
   "source": [
    "sixway_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=1.e-4), metrics=['acc'])\n",
    "sixway_history = sixway_model.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
    "                                  batch_size=batch_size, callbacks=callbacks, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOrVmbxAAztY"
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235,
     "status": "error",
     "timestamp": 1565029515849,
     "user": {
      "displayName": "ANIRUDH SRINIVASAN CHAKRAVARTHY",
      "photoUrl": "",
      "userId": "15662816526463818185"
     },
     "user_tz": -330
    },
    "id": "os5SBjRFdBvU",
    "outputId": "1c7f87bf-a655-40f9-c018-7652bf74228c"
   },
   "outputs": [],
   "source": [
    "x_test, y_test = sjplus_condition(test_df, classifier)\n",
    "\n",
    "sixway_model.load_weights('fake_news_sixway_2385.hdf5')\n",
    "score, acc = sixway_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsqN5CliDXCl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Fake News Sixway Classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
